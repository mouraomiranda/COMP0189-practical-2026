{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdanny/COMP0189-practical/blob/main/Week-06/deepglobe_land_cover_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IlD1eeQItn",
        "papermill": {
          "duration": 0.024489,
          "end_time": "2020-11-11T04:19:40.496749",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.472260",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "# COMP0189: Applied Artificial Intelligence\n",
        "## Week 6 (Deep Learning - image segmentation)\n",
        "\n",
        "In this notebook we use [Unet](https://arxiv.org/abs/1505.04597) for Land Cover Classfication from Satellite Imagery using [DeepGlobe Land Cover Classification Dataset](https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq2w-_Gb1zTm"
      },
      "source": [
        "**Land cover classification** involves analysing satellite images and segmenting them into regions based on their land cover type. These types include urban areas, forests, water bodies, and more. Segmentation **assigns a class label to each pixel**, creating detailed, colour-coded maps of land use.\n",
        "\n",
        "For example:\n",
        "- Pixels representing urban areas are assigned the RGB value (0, 255, 255).\n",
        "- Pixels representing water are assigned the RGB value (0, 0, 255).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQj6Y2k810qI"
      },
      "source": [
        "After this week you will be able to ...\n",
        "\n",
        "- Train U-Net models in PyTorch.\n",
        "- Implement Dice loss and BCE-Dice loss.\n",
        "- Visualize the prediction output on some of the test images using the trained U-Net.\n",
        "- Learn how data augmentation affects model training.\n",
        "- Compute the area of one class on the test set ground truth, the same class on the predicted masks on the same test set, and compute the difference between the two to see the error of your predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Before you start\n",
        "**You first need to download the dataset from its [Kaggle page](https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset)**. Download it as a zip file, then extract it into a `data` directory in the same folder as this notebook.\n",
        "\n",
        "Also download the 3 pre-trained models from [here](https://liveuclac-my.sharepoint.com/:f:/g/personal/ucabc25_ucl_ac_uk/IgDo81wmIbrzRI4x0MEl_t5HARv5MkQk_NP6yIRPz9CzTNU?e=14yD8Q) and place them in the same folder as the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbTqV1tQIto",
        "papermill": {
          "duration": 0.022878,
          "end_time": "2020-11-11T04:19:40.542961",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.520083",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Libraries üìö‚¨á"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZZjQKj93uQA",
        "outputId": "cca927b2-5b37-4614-bbed-d57d0bec6b0a"
      },
      "outputs": [],
      "source": [
        "%pip install segmentation-models-pytorch==0.5.0 opencv-python==4.13.0.92 albumentations==2.0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-11-11T04:19:40.598993Z",
          "iopub.status.busy": "2020-11-11T04:19:40.598327Z",
          "iopub.status.idle": "2020-11-11T04:19:43.727682Z",
          "shell.execute_reply": "2020-11-11T04:19:43.726567Z"
        },
        "id": "Cd_Q_EbIQItp",
        "papermill": {
          "duration": 3.161749,
          "end_time": "2020-11-11T04:19:43.727814",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.566065",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JuDPChTQItq",
        "papermill": {
          "duration": 0.023301,
          "end_time": "2020-11-11T04:20:00.708750",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.685449",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Read Data & Create train / valid splits üìÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ4cH84Ey8y-"
      },
      "source": [
        "We previously downloaded the datasets metadata files.\n",
        "\n",
        "`metadata.csv` reports the image IDs, image paths, which split they belong to, and the path to the segmentation mask (label).  \n",
        "`class_dict.csv` reports the RGB colour code for each of the 7 possible classes in the segmentation masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2YU1w3lkzRHy",
        "outputId": "ff03eddb-298f-4e39-fb3c-2b8c9ed422f1"
      },
      "outputs": [],
      "source": [
        "# Change this if necessary to the directory where you extracted the dataset\n",
        "DATA_DIR = './data'\n",
        "\n",
        "# Load metadata into df\n",
        "metadata_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\n",
        "metadata_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p0pZc1SWzRpD",
        "outputId": "1fd5950e-da54-4c95-9f4c-8044d173e6c9"
      },
      "outputs": [],
      "source": [
        "# Load class info into df\n",
        "class_dict_df = pd.read_csv(os.path.join(DATA_DIR, 'class_dict.csv'))\n",
        "\n",
        "class_dict_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Ru8Ru2ztKI"
      },
      "source": [
        "Use the metadata to create your data splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.768015Z",
          "iopub.status.busy": "2020-11-11T04:20:00.767115Z",
          "iopub.status.idle": "2020-11-11T04:20:00.796084Z",
          "shell.execute_reply": "2020-11-11T04:20:00.796568Z"
        },
        "id": "ogMMvJUBQItr",
        "outputId": "b6d34226-14f0-4a4d-da66-9f39f9226333",
        "papermill": {
          "duration": 0.064492,
          "end_time": "2020-11-11T04:20:00.796691",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.732199",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get train set & select relevant columns\n",
        "metadata_df = metadata_df[metadata_df['split']=='train']\n",
        "metadata_df = metadata_df[['image_id', 'sat_image_path', 'mask_path']]\n",
        "\n",
        "# Update paths\n",
        "metadata_df['sat_image_path'] = metadata_df['sat_image_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "metadata_df['mask_path'] = metadata_df['mask_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "\n",
        "# Shuffle dataframe\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Perform 80/20 split for train / test\n",
        "test_df = metadata_df.sample(frac=0.2, random_state=42)\n",
        "train_df = metadata_df.drop(test_df.index)\n",
        "\n",
        "# Perform 90/10 split for train / val\n",
        "valid_df = train_df.sample(frac=0.1, random_state=42)\n",
        "train_df = train_df.drop(valid_df.index)\n",
        "\n",
        "# Check number of samples\n",
        "print('Train / test / val samples:')\n",
        "print(len(train_df), '/', len(test_df), '/', len(valid_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQZ0TSc15vE6"
      },
      "source": [
        "Extract label information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.852070Z",
          "iopub.status.busy": "2020-11-11T04:20:00.851216Z",
          "iopub.status.idle": "2020-11-11T04:20:00.860652Z",
          "shell.execute_reply": "2020-11-11T04:20:00.859981Z"
        },
        "id": "PrS7OOwqQIts",
        "outputId": "be524a7e-677e-42c9-efa3-3df4f31a44b2",
        "papermill": {
          "duration": 0.03956,
          "end_time": "2020-11-11T04:20:00.860779",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.821219",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get class names\n",
        "class_names = class_dict_df['name'].tolist()\n",
        "# Get class RGB values\n",
        "class_rgb_values = class_dict_df[['r','g','b']].values.tolist()\n",
        "\n",
        "print('All dataset classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_eVnHo2QIts",
        "papermill": {
          "duration": 0.024557,
          "end_time": "2020-11-11T04:20:00.910401",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.885844",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Shortlist specific classes to segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.966519Z",
          "iopub.status.busy": "2020-11-11T04:20:00.965617Z",
          "iopub.status.idle": "2020-11-11T04:20:00.970796Z",
          "shell.execute_reply": "2020-11-11T04:20:00.970160Z"
        },
        "id": "K55PxIauQItt",
        "outputId": "e2b9db1e-1af1-498c-aec2-a52bca933e91",
        "papermill": {
          "duration": 0.036145,
          "end_time": "2020-11-11T04:20:00.970921",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.934776",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Useful to shortlist specific classes in datasets with large number of classes\n",
        "select_classes = ['urban_land', 'agriculture_land', 'rangeland', 'forest_land', 'water', 'barren_land', 'unknown']\n",
        "\n",
        "# Get RGB values of required classes\n",
        "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
        "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
        "\n",
        "print('Selected classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGCpfjsQItt",
        "papermill": {
          "duration": 0.024734,
          "end_time": "2020-11-11T04:20:01.021071",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.996337",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Helper functions for viz. & one-hot encoding/decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.080389Z",
          "iopub.status.busy": "2020-11-11T04:20:01.079533Z",
          "iopub.status.idle": "2020-11-11T04:20:01.088228Z",
          "shell.execute_reply": "2020-11-11T04:20:01.087750Z"
        },
        "id": "59bU68D0QItt",
        "papermill": {
          "duration": 0.042035,
          "end_time": "2020-11-11T04:20:01.088327",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.046292",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"\n",
        "    Plot images in one row\n",
        "    \"\"\"\n",
        "    n_images = len(images)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n_images, idx + 1)\n",
        "        plt.xticks([]);\n",
        "        plt.yticks([])\n",
        "        # get title from the parameter names\n",
        "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Perform one hot encoding on label\n",
        "def one_hot_encode(label, label_values):\n",
        "    \"\"\"\n",
        "    Convert a segmentation image label array to one-hot format\n",
        "    by replacing each pixel value with a vector of length num_classes\n",
        "    # Arguments\n",
        "        label: The 2D array segmentation image label\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of num_classes\n",
        "    \"\"\"\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map\n",
        "\n",
        "# Perform reverse one-hot-encoding on labels / preds\n",
        "def reverse_one_hot(image):\n",
        "    \"\"\"\n",
        "    Transform a 2D array in one-hot format (depth is num_classes),\n",
        "    to a 2D array with only 1 channel, where each pixel value is\n",
        "    the classified class key.\n",
        "    # Arguments\n",
        "        image: The one-hot format image\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of 1, where each pixel value is the classified\n",
        "        class key.\n",
        "    \"\"\"\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "# Perform colour coding on the reverse-one-hot outputs\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    \"\"\"\n",
        "    Given a 1-channel array of class keys, colour code the segmentation results.\n",
        "    # Arguments\n",
        "        image: single channel array where each value represents the class key.\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        Colour coded image for segmentation visualization\n",
        "    \"\"\"\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "714IWFiotSka"
      },
      "source": [
        "## Custom Dataset class\n",
        "Pytorch has utilities that help us create well-structured datsets, which is important for computer vision tasks.\n",
        "\n",
        "This class inherits from `torch.utils.data.Dataset` and allows us to put together a dataset class that handles:\n",
        "- reading the satellite images and their corresponding segmentation masks\n",
        "- preprocessing such as one-hot encoding the segmentation masks\n",
        "- any desired operations on the data, such as augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.142187Z",
          "iopub.status.busy": "2020-11-11T04:20:01.141334Z",
          "iopub.status.idle": "2020-11-11T04:20:01.153771Z",
          "shell.execute_reply": "2020-11-11T04:20:01.154347Z"
        },
        "id": "N2Zf_hGOQItu",
        "papermill": {
          "duration": 0.041149,
          "end_time": "2020-11-11T04:20:01.154457",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.113308",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LandCoverDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    \"\"\"DeepGlobe Land Cover Classification Challenge Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "\n",
        "    Args:\n",
        "        df (str): DataFrame containing images / labels paths\n",
        "        class_rgb_values (list): RGB values of select classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline\n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing\n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            df,\n",
        "            class_rgb_values=None,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.image_paths = df['sat_image_path'].tolist()\n",
        "        self.mask_paths = df['mask_path'].tolist()\n",
        "\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # read images and masks\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # one-hot-encode the mask\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        # return length of\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ld70i2QItv",
        "papermill": {
          "duration": 0.0248,
          "end_time": "2020-11-11T04:20:01.204614",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.179814",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Sample Image and Mask üìà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.262566Z",
          "iopub.status.busy": "2020-11-11T04:20:01.261449Z",
          "iopub.status.idle": "2020-11-11T04:20:04.972786Z",
          "shell.execute_reply": "2020-11-11T04:20:04.972272Z"
        },
        "id": "EBC4RuDuQItv",
        "outputId": "3b654762-412b-4628-c65e-f5cdaa16bda2",
        "papermill": {
          "duration": 3.743046,
          "end_time": "2020-11-11T04:20:04.972888",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.229842",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset\n",
        "dataset = LandCoverDataset(train_df, class_rgb_values=select_class_rgb_values)\n",
        "\n",
        "# Sample a random image to visualise\n",
        "random_idx = random.randint(0, len(dataset)-1)\n",
        "image, mask = dataset[random_idx]\n",
        "\n",
        "# Use helper function defined earlier to inspect image\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13lJ1tyTQItw",
        "papermill": {
          "duration": 0.031599,
          "end_time": "2020-11-11T04:20:05.037746",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.006147",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Defining Augmentation and preprocessing pipeline for data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.112791Z",
          "iopub.status.busy": "2020-11-11T04:20:05.111981Z",
          "iopub.status.idle": "2020-11-11T04:20:05.115075Z",
          "shell.execute_reply": "2020-11-11T04:20:05.114478Z"
        },
        "id": "VQQlWcOtQItw",
        "papermill": {
          "duration": 0.045522,
          "end_time": "2020-11-11T04:20:05.115181",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.069659",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        album.RandomCrop(height=1024, width=1024, always_apply=True),\n",
        "        album.HorizontalFlip(p=0.5),\n",
        "        album.VerticalFlip(p=0.5),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_training_no_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    Args:\n",
        "        preprocessing_fn (callable): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \"\"\"\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "\n",
        "    return album.Compose(_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhkhbBjgQItx",
        "papermill": {
          "duration": 0.03172,
          "end_time": "2020-11-11T04:20:05.179602",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.147882",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Augmented Images & Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.250381Z",
          "iopub.status.busy": "2020-11-11T04:20:05.249704Z",
          "iopub.status.idle": "2020-11-11T04:20:11.456620Z",
          "shell.execute_reply": "2020-11-11T04:20:11.457108Z"
        },
        "id": "eiKMEI5DQIty",
        "outputId": "11765c3d-99de-49e7-ba10-7d50439fb54f",
        "papermill": {
          "duration": 6.245534,
          "end_time": "2020-11-11T04:20:11.457241",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.211707",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "augmented_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "image, mask = augmented_dataset[random_idx]\n",
        "visualize(\n",
        "        original_image = image,\n",
        "        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "        one_hot_encoded_mask = reverse_one_hot(mask))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEU8DKdFQIty",
        "papermill": {
          "duration": 0.05496,
          "end_time": "2020-11-11T04:20:11.565134",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.510174",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wWLNIJdQItz",
        "papermill": {
          "duration": 0.052843,
          "end_time": "2020-11-11T04:20:11.772393",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.719550",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:11.881284Z",
          "iopub.status.busy": "2020-11-11T04:20:11.880373Z",
          "iopub.status.idle": "2020-11-11T04:20:17.009902Z",
          "shell.execute_reply": "2020-11-11T04:20:17.009318Z"
        },
        "id": "a3ZHSlQyQItz",
        "outputId": "6664af63-b083-4f56-8442-4db6a685aadd",
        "papermill": {
          "duration": 5.187035,
          "end_time": "2020-11-11T04:20:17.010064",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.823029",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = select_classes\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=ENCODER_WEIGHTS,     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    classes=len(CLASSES),\n",
        "    activation=ACTIVATION,# model output channels (number of classes in your dataset)\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NKfm2i9QIt0",
        "papermill": {
          "duration": 0.050739,
          "end_time": "2020-11-11T04:20:17.327158",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.276419",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Task 1: Diceloss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRpE6rV_Gy0"
      },
      "source": [
        "Implement the 1-dice loss\n",
        "(https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3W7EY0PNiwi"
      },
      "outputs": [],
      "source": [
        "def f_score(pr, gt, beta=1.0, eps=1e-7, threshold=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pr (torch.Tensor): Predicted probabilities [0,1], shape (B, C, H, W)\n",
        "        gt (torch.Tensor): Ground truth binary mask, same shape\n",
        "        beta (float): Weight for precision-recall balance (1.0 = balanced)\n",
        "        eps (float): Small epsilon for numerical stability\n",
        "        threshold (float or None): Threshold for binarization (if needed)\n",
        "    \"\"\"\n",
        "\n",
        "    # Your code here...\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Soft Dice Loss for segmentation tasks.\"\"\"\n",
        "    __name__ = 'dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            eps (float): Epsilon for numerical stability.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        \"\"\"\n",
        "        y_pr: probabilities from the model (B, C, H, W)\n",
        "        y_gt: ground truth binary mask (B, C, H, W)\n",
        "        \"\"\"\n",
        "        # Your code here...\n",
        "\n",
        "\n",
        "class BCEDiceLoss(DiceLoss):\n",
        "    \"\"\"Combination of BCELoss + Dice Loss.\"\"\"\n",
        "    __name__ = 'bce_dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, lambda_dice=1.0, lambda_bce=1.0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            eps (float): Epsilon for numerical stability in Dice.\n",
        "            lambda_dice (float): Weight of Dice loss.\n",
        "            lambda_bce (float): Weight of BCE loss.\n",
        "        \"\"\"\n",
        "        super().__init__(eps)\n",
        "        self.lambda_dice = lambda_dice\n",
        "        self.lambda_bce = lambda_bce\n",
        "\n",
        "        # Since the model outputs probabilities, we use BCELoss (NOT BCEWithLogitsLoss)\n",
        "        self.bce = nn.BCELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        \"\"\"\n",
        "        y_pr: probabilities from the model (B, C, H, W)\n",
        "        y_gt: ground truth binary mask (B, C, H, W)\n",
        "        \"\"\"\n",
        "        # Your code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLRswvhTFNL"
      },
      "source": [
        "# Task 2: To see the effect of data augmentation, we will do ablation. Let's train the model without the data augmentation.\n",
        "\n",
        "By not passing the `augmentation` parameter when initializing the `LandCoverDataset`, you can create a data loader that does not contain the augmented image data. However, in this notebook (for educational purpose), just to resize the image, we created a separate function (`get_training_no_augmentation()`). Passing an image without resizing it will cause memory error as the image size is bigger than the Colab's GPU capacity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWoMas6WKL8n"
      },
      "source": [
        "## 2.1 Dataset and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KArxixSgTI6i"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances\n",
        "train_dataset_without_aug = LandCoverDataset(train_df,augmentation=get_training_no_augmentation(),\n",
        "                                                  preprocessing=get_preprocessing(preprocessing_fn),\n",
        "                                                   class_rgb_values=select_class_rgb_values)\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# Create test dataset instance\n",
        "test_dataset = LandCoverDataset(\n",
        "    test_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# Create dataloaders for train, val and test datasets\n",
        "train_loader = DataLoader(train_dataset_without_aug, batch_size=2, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ckT3WhAJXtD"
      },
      "source": [
        "Visualise test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "KFoC0N0dqUSr",
        "outputId": "1c66e5d0-b285-484c-a3d7-ee9fcf6cb3bb"
      },
      "outputs": [],
      "source": [
        "# test dataset for visualization (without preprocessing augmentations & transformations)\n",
        "test_dataset_vis = LandCoverDataset(\n",
        "    test_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# get a random test image/mask index\n",
        "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
        "image, mask = test_dataset_vis[random_idx]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLuT8KsLJgiV"
      },
      "source": [
        "## 2.2 Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXW6AI4zThcs"
      },
      "outputs": [],
      "source": [
        "from segmentation_models_pytorch import utils as seg_utils\n",
        "\n",
        "# Set flag to train the model or not. If set to 'False', only prediction is performed.\n",
        "TRAINING = False\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 30\n",
        "\n",
        "# Set device: `cuda` for GPU or `cpu` for CPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define loss function used during training\n",
        "loss = DiceLoss()\n",
        "\n",
        "# Define evaluation metrics\n",
        "metrics = [\n",
        "    seg_utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.001),\n",
        "])\n",
        "\n",
        "# Define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n",
        "# # load best saved model checkpoint from previous commit (if present)\n",
        "# if os.path.exists('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth'):\n",
        "#     model = torch.load('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "#     print('Loaded pre-trained DeepLabV3+ model!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSs5ErLKmsF"
      },
      "source": [
        "Setup training process for one epoch using Pytorch helper class `smp.utils.train.TrainEpoch`.\n",
        "\n",
        "This helps handle the forward pass, loss calculation, backpropagation, and weight updates for each batch of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n90G1-alTp8z"
      },
      "outputs": [],
      "source": [
        "train_epoch = seg_utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = seg_utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-_b9gYkLEQt"
      },
      "source": [
        "## 2.3 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfc_Pxf2TmwY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKDU4ylYDdZx"
      },
      "outputs": [],
      "source": [
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwvavB1rTyjT"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "if TRAINING:\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i + 1))  # Change to 1-based indexing for clarity\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './no_aug_30_epochs.pth')\n",
        "            print('Model saved!')\n",
        "\n",
        "        # Ensure learning rate scheduler is stepped\n",
        "        lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNU-682jL5uc"
      },
      "source": [
        "## 2.4 Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt5xYeOCavhe",
        "outputId": "01166c5a-5016-4558-c85a-b39d6c8ed41f"
      },
      "outputs": [],
      "source": [
        "# load best model (or pretrained model)\n",
        "if os.path.exists('./no_aug_30_epochs.pth'):\n",
        "    best_model = torch.load('./no_aug_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK8cvvRuT-BR",
        "outputId": "b7aebb7b-7e77-46c7-838c-a16d7c03c5e2"
      },
      "outputs": [],
      "source": [
        "test_epoch = seg_utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhdoQ0MTWLcl"
      },
      "outputs": [],
      "source": [
        "sample_preds_folder = 'sample_predictions/'\n",
        "if not os.path.exists(sample_preds_folder):\n",
        "    os.makedirs(sample_preds_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFe8ZdG6WL6b"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V6UKYQm2WNSh",
        "outputId": "053f32ad-68d2-4b6b-f14f-c2efc2478227"
      },
      "outputs": [],
      "source": [
        "for idx in range(7):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_urban_land_heatmap = pred_mask[:,:,select_classes.index('urban_land')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "\n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_urban_land_heatmap = pred_urban_land_heatmap\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "7jfU7DC9eLXu",
        "outputId": "6fd82e4c-68dd-43d2-bf52-78ea9911cbc3"
      },
      "outputs": [],
      "source": [
        "def compute_iou(pr, gt, eps=1e-7):\n",
        "    \"\"\"\n",
        "    Compute per-class IoU (Jaccard Index).\n",
        "\n",
        "    Args:\n",
        "        pr (torch.Tensor): Predicted tensor (binary mask), shape (B, C, H, W)\n",
        "        gt (torch.Tensor): Ground truth tensor (binary mask), shape (B, C, H, W)\n",
        "        eps (float): Small epsilon for numerical stability\n",
        "\n",
        "    Returns:\n",
        "        list: IoU scores per class\n",
        "    \"\"\"\n",
        "    num_classes = pr.shape[1]\n",
        "    iou_scores = []\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        pr_c = pr[:, c, :, :]  # Get spatial map for class c\n",
        "        gt_c = gt[:, c, :, :]  # Get spatial map for class c\n",
        "\n",
        "        intersection = torch.sum(pr_c * gt_c)\n",
        "        union = torch.sum(pr_c) + torch.sum(gt_c) - intersection\n",
        "\n",
        "        iou = (intersection + eps) / (union + eps)\n",
        "        iou_scores.append(iou.item())\n",
        "\n",
        "    return iou_scores\n",
        "\n",
        "\n",
        "def evaluate_per_class_metrics(model, dataloader, device, class_names):\n",
        "    \"\"\"\n",
        "    Compute the average Dice Score and IoU per class for the best model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained segmentation model.\n",
        "        dataloader (torch.utils.data.DataLoader): Dataloader for test data.\n",
        "        device (torch.device): Device (CPU or CUDA).\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing per-class Dice Score and IoU.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Track dataset-wide totals for intersection, union, dice\n",
        "    total_intersections = {cls: 0 for cls in class_names}\n",
        "    total_unions = {cls: 0 for cls in class_names}\n",
        "    total_dice_numerator = {cls: 0 for cls in class_names}\n",
        "    total_dice_denominator = {cls: 0 for cls in class_names}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images, masks = images.to(device), masks.to(device).float()\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)  # Convert logits to probabilities\n",
        "\n",
        "            # Binarize predictions\n",
        "            binarized_preds = (preds > 0.5).float()\n",
        "\n",
        "            # Compute per-class metrics\n",
        "            for i, cls in enumerate(class_names):\n",
        "                pr_c = binarized_preds[:, i, :, :]  # Predicted class mask\n",
        "                gt_c = masks[:, i, :, :]  # Ground truth class mask\n",
        "\n",
        "                # Compute IoU\n",
        "                intersection = torch.sum(pr_c * gt_c).item()\n",
        "                union = torch.sum(pr_c).item() + torch.sum(gt_c).item() - intersection\n",
        "\n",
        "                # Compute Dice Score\n",
        "                dice_numerator = 2 * intersection\n",
        "                dice_denominator = torch.sum(pr_c).item() + torch.sum(gt_c).item()\n",
        "\n",
        "                # Store dataset-wide sums\n",
        "                total_intersections[cls] += intersection\n",
        "                total_unions[cls] += union\n",
        "                total_dice_numerator[cls] += dice_numerator\n",
        "                total_dice_denominator[cls] += dice_denominator\n",
        "\n",
        "    # Compute dataset-wide IoU & Dice per class\n",
        "    avg_iou = {\n",
        "        cls: (total_intersections[cls] / total_unions[cls]) if total_unions[cls] > 0 else np.nan\n",
        "        for cls in class_names\n",
        "    }\n",
        "    avg_dice = {\n",
        "        cls: (total_dice_numerator[cls] / total_dice_denominator[cls]) if total_dice_denominator[cls] > 0 else np.nan\n",
        "        for cls in class_names\n",
        "    }\n",
        "\n",
        "    # Compute overall mean (ignoring NaN values)\n",
        "    overall_mean_iou = np.nanmean(list(avg_iou.values()))  # Ignores NaNs\n",
        "    overall_mean_dice = np.nanmean(list(avg_dice.values()))\n",
        "\n",
        "    # Create DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        \"Class\": class_names,\n",
        "        \"Avg Dice Score\": [avg_dice[cls] for cls in class_names],\n",
        "        \"Avg IoU Score\": [avg_iou[cls] for cls in class_names]\n",
        "    })\n",
        "\n",
        "    print(f\"\\nOverall Mean Dice Score: {overall_mean_dice:.4f}\")\n",
        "    print(f\"Overall Mean IoU Score: {overall_mean_iou:.4f}\")\n",
        "\n",
        "    return df_metrics\n",
        "\n",
        "\n",
        "# Run the evaluation\n",
        "# Your code here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4Xa46wSkvG"
      },
      "source": [
        "# Task 3: Train the model with the data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKveJfkQjC1i"
      },
      "source": [
        "## 3.1 Dataset and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxTWxR33qiZQ"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    test_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCq7pXdmjo1g"
      },
      "source": [
        "## 3.2 Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:17.806622Z",
          "iopub.status.busy": "2020-11-11T04:20:17.805771Z",
          "iopub.status.idle": "2020-11-11T04:20:21.985521Z",
          "shell.execute_reply": "2020-11-11T04:20:21.986028Z"
        },
        "id": "OnVwfVknQIt1",
        "papermill": {
          "duration": 4.6083,
          "end_time": "2020-11-11T04:20:21.986189",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.377889",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = False\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 30\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# loss = smp.utils.losses.DiceLoss()\n",
        "loss = DiceLoss()\n",
        "\n",
        "# loss = BCEDiceLoss()\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    seg_utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.001),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.099274Z",
          "iopub.status.busy": "2020-11-11T04:20:22.098455Z",
          "iopub.status.idle": "2020-11-11T04:20:22.121316Z",
          "shell.execute_reply": "2020-11-11T04:20:22.120427Z"
        },
        "id": "uO7_OACaQIt1",
        "papermill": {
          "duration": 0.082187,
          "end_time": "2020-11-11T04:20:22.121494",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.039307",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_epoch = seg_utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = seg_utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iknaFwFojt8R"
      },
      "source": [
        "## 3.3 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-u_RqwkdZrL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.346852Z",
          "iopub.status.busy": "2020-11-11T04:20:22.345942Z",
          "iopub.status.idle": "2020-11-11T05:54:51.737107Z",
          "shell.execute_reply": "2020-11-11T05:54:51.736560Z"
        },
        "id": "IutdGndaQIt2",
        "outputId": "16df5b50-ce5c-43d8-b00b-705e96201161",
        "papermill": {
          "duration": 5669.449912,
          "end_time": "2020-11-11T05:54:51.737233",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.287321",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "if TRAINING:\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "    for i in range(0, EPOCHS):\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './aug_30_epochs.pth')\n",
        "            print('Model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXQDtyWQjxEm"
      },
      "source": [
        "## 3.4 Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T05:54:55.915262Z",
          "iopub.status.busy": "2020-11-11T05:54:55.914377Z",
          "iopub.status.idle": "2020-11-11T05:54:56.035770Z",
          "shell.execute_reply": "2020-11-11T05:54:56.036521Z"
        },
        "id": "acA_0-BwQIt2",
        "outputId": "9f625db3-4649-4016-c5bf-6aca99b10b2b",
        "papermill": {
          "duration": 1.141206,
          "end_time": "2020-11-11T05:54:56.036700",
          "exception": false,
          "start_time": "2020-11-11T05:54:54.895494",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load best saved model checkpoint from the current run\n",
        "if os.path.exists('./aug_30_epochs.pth'):\n",
        "    best_model = torch.load('./aug_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2XvVrd_aRE"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T05:55:06.975351Z",
          "iopub.status.busy": "2020-11-11T05:55:06.974233Z",
          "iopub.status.idle": "2020-11-11T06:00:23.885708Z",
          "shell.execute_reply": "2020-11-11T06:00:23.884781Z"
        },
        "id": "QVvVZ9ccQIt4",
        "outputId": "791ce806-89ff-402a-a5f6-8a735150615a",
        "papermill": {
          "duration": 318.110868,
          "end_time": "2020-11-11T06:00:23.885824",
          "exception": false,
          "start_time": "2020-11-11T05:55:05.774956",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "for idx in range(7):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_urban_land_heatmap = pred_mask[:,:,select_classes.index('urban_land')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "\n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_urban_land_heatmap = pred_urban_land_heatmap\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T06:00:29.779356Z",
          "iopub.status.busy": "2020-11-11T06:00:29.778414Z",
          "iopub.status.idle": "2020-11-11T06:02:40.900735Z",
          "shell.execute_reply": "2020-11-11T06:02:40.897939Z"
        },
        "id": "FICx4seLQIt5",
        "outputId": "c5db6a40-cd5d-4a67-ba4d-7e13d1139fd8",
        "papermill": {
          "duration": 132.588372,
          "end_time": "2020-11-11T06:02:40.900910",
          "exception": false,
          "start_time": "2020-11-11T06:00:28.312538",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_epoch = seg_utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ7bRTP6fUb-",
        "outputId": "25083efc-158e-468a-f196-3079c7c3d5c0"
      },
      "outputs": [],
      "source": [
        "# Your code here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTATaD7IfZt7",
        "outputId": "44455e57-438a-4d6d-f643-2d1a28617092"
      },
      "outputs": [],
      "source": [
        "# compare with augmentation to without augmentation:\n",
        "# Merge results into a single DataFrame for better comparison\n",
        "df_comparison = pd.merge(df_results_no_aug, df_results_aug, on=\"Class\", suffixes=(\"_No_Aug\", \"_Aug\"))\n",
        "\n",
        "# Rename columns for clarity\n",
        "df_comparison.rename(columns={\n",
        "    \"Avg Dice Score_No_Aug\": \"Dice Score (No Aug)\",\n",
        "    \"Avg Dice Score_Aug\": \"Dice Score (Aug)\",\n",
        "    \"Avg IoU Score_No_Aug\": \"IoU Score (No Aug)\",\n",
        "    \"Avg IoU Score_Aug\": \"IoU Score (Aug)\"\n",
        "}, inplace=True)\n",
        "\n",
        "df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZDOec7ZOxGX"
      },
      "source": [
        "# Task 4: Loss comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyOzaq-6tnyB"
      },
      "source": [
        "### Now, let's try with different loss function: Dice Loss vs BCE Loss.\n",
        "\n",
        "You can try implementing or importing different loss functions from pytorch library.  \n",
        "Also, here's a survey for loss functions used for image segmentation: https://arxiv.org/pdf/2006.14822.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umoWmCNIj9r-"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    test_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HiKxTtMOze-"
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = False\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 30\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# setting dice to zero means purce bce ... use combination if interested in effect of combining\n",
        "loss = BCEDiceLoss(lambda_dice=0.0)\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    seg_utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.001),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MBHg_qIO9b5"
      },
      "outputs": [],
      "source": [
        "train_epoch = seg_utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = seg_utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0UrZHjiPBON"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G75L-7HqPFDG",
        "outputId": "3c87ed89-07ab-4790-9a90-550603586916"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './bceloss_30_epochs.pth')\n",
        "            print('Model saved!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqI_Ig5Nicr6",
        "outputId": "57318ccf-c149-4a87-9314-ebedecc715d4"
      },
      "outputs": [],
      "source": [
        "# load best saved model checkpoint from the current run\n",
        "if os.path.exists('./bceloss_30_epochs.pth'):\n",
        "    best_model = torch.load('./bceloss_30_epochs.pth', weights_only=False, map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yykVXiHKPyFu",
        "outputId": "ac8b0234-88bc-475a-a36c-70ff85642f00"
      },
      "outputs": [],
      "source": [
        "test_epoch = seg_utils.train.ValidEpoch(\n",
        "    best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['bce_dice_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb6cWOL7i5xB",
        "outputId": "a06f83a3-f049-4ee3-8626-93142f52bc05"
      },
      "outputs": [],
      "source": [
        "# Your code here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEuQ7TPBTE0u",
        "outputId": "996c5ea6-ab09-4d57-92b3-7e63b0a9e0cd"
      },
      "outputs": [],
      "source": [
        "# compare with dice to bce:\n",
        "# Merge results into a single DataFrame for better comparison\n",
        "df_comparison = pd.merge(df_results_aug, df_results_bce, on=\"Class\", suffixes=(\"_Dice\", \"_BCE\"))\n",
        "\n",
        "# Rename columns for clarity\n",
        "df_comparison.rename(columns={\n",
        "    \"Avg Dice Score_Dice\": \"Dice Score (Dice)\",\n",
        "    \"Avg Dice Score_BCE\": \"Dice Score (BCE)\",\n",
        "    \"Avg IoU Score_Dice\": \"IoU Score (Dice)\",\n",
        "    \"Avg IoU Score_BCE\": \"IoU Score (BCE)\"\n",
        "}, inplace=True)\n",
        "\n",
        "df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62UgBVoulNM"
      },
      "source": [
        "**Discussion**  \n",
        "We have trained the same model with two different losses: Diceloss and BCEloss.\n",
        "\n",
        "What difference do you see from the IOU score?   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I216sWjnh0Mo"
      },
      "source": [
        "# Task 5: compute the average area difference between actual and predicted classes\n",
        "\n",
        "\n",
        "Hint: base area on pixel.\n",
        "https://stackoverflow.com/questions/58068315/calculate-the-area-of-the-masks-in-pixels-in-grey-scale-images-with-python\n",
        "\n",
        "**Question**: What is the error of your predictions in terms of water area/surface?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CICJ73mfl6p3",
        "outputId": "9572af98-d710-4986-c65c-cfa3b7953c29"
      },
      "outputs": [],
      "source": [
        "def compute_average_area_difference(model, dataloader, device, class_names):\n",
        "    \"\"\"\n",
        "    Compute the average area difference (per class) between predicted and ground truth masks.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Trained segmentation model.\n",
        "        dataloader (torch.utils.data.DataLoader): Test dataloader.\n",
        "        device (torch.device): CPU or GPU.\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Table containing average area difference per class.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize dictionary to store sum of differences\n",
        "    total_area_diffs = {cls: 0 for cls in class_names}\n",
        "    num_test_images = len(dataloader.dataset)  # Get total test images\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.cpu().numpy()  # Move ground truth masks to CPU\n",
        "            masks = (masks > 0).astype(np.uint8)  # Ensure binary ground truth masks\n",
        "\n",
        "            # Get predictions\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)  # Convert logits to probabilities\n",
        "            preds = (preds > 0.5).float().cpu().numpy()  # Convert to binary masks\n",
        "\n",
        "            # Loop over batch\n",
        "            batch_size = images.shape[0]\n",
        "            for b in range(batch_size):\n",
        "                # Iterate through each class\n",
        "                for i, cls in enumerate(class_names):\n",
        "                    # Extract single-channel binary masks for the class\n",
        "                    pred_mask = preds[b, i].astype(np.uint8)  # Predicted class mask\n",
        "                    gt_mask = masks[b, i].astype(np.uint8)  # GT class mask\n",
        "\n",
        "                    # Compute absolute difference in area\n",
        "                    \n",
        "                    # Your code here... \n",
        "\n",
        "    # Compute mean area difference per class (normalize by number of images)\n",
        "    avg_area_diff = {cls: total_area_diffs[cls] / num_test_images for cls in class_names}\n",
        "\n",
        "    # Create a DataFrame for visualization\n",
        "    df_area_difference = pd.DataFrame({\n",
        "        \"Class\": class_names,\n",
        "        \"Avg Area Difference (Pixels)\": [avg_area_diff[cls] for cls in class_names]\n",
        "    })\n",
        "\n",
        "    return df_area_difference\n",
        "\n",
        "# Run the function to compute area differences\n",
        "df_area_diff = compute_average_area_difference(best_model, test_dataloader, DEVICE, select_classes)\n",
        "\n",
        "df_area_diff"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "papermill": {
      "duration": 6201.325856,
      "end_time": "2020-11-11T06:02:57.609445",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-11T04:19:36.283589",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
