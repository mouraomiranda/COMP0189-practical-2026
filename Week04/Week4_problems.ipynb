{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uyu0ma5quxjS"
   },
   "source": [
    "# COMP0189: Applied Artificial Intelligence\n",
    "## Week 4 (Linear models, Trees and Ensemble Models)\n",
    "\n",
    "## ðŸŽ¯ Learning goals\n",
    "1. Apply various regularized linear models to tabular data and optimize their regularization hyperparameter properly\n",
    "2. Learn how to visualize the coefficients of linear models\n",
    "3. Apply various tree based and ensemble models to tabular data\n",
    "4. Learn how to visualize feature importance for tree based models\n",
    "5. Learn how to plot data on a map\n",
    "\n",
    "### Dataset\n",
    "We will use the [Womxn in Big Data South Africa: Female-Headed Households in South Africa](https://zindi.africa/competitions/womxn-in-big-data-south-africa-female-headed-households-in-south-africa) challenge from the Zindi platform.\n",
    "\n",
    "The challenge associated with this dataset consists of developing a Machine Learning model that using the dataset features can predict the percentage of female-headed households in a ward that have an annual income lower than approximately 2.3 thousand dollars at the time the data was collected.\n",
    "\n",
    "The dataset has been developed using the data from the 2011 census in South Africa by aggregating key indicators that may be relevant in the context of the proposed task and that intuitively should have some connections - e.g. home type, school attendance, access to piped water, language, etc.\n",
    "\n",
    "South Africa comprises over 4 thousand wards (i.e. geopolitical subdivisions of the country), and each feature in the dataset represents information about a specific ward, such as the prevalence of different types of dwellings or the prevalence of different population groups.\n",
    "\n",
    "### Acknowledgements\n",
    "- https://scikit-learn.org/stable/\n",
    "- https://zindi.africa/competitions/womxn-in-big-data-south-africa-female-headed-households-in-south-africa \n",
    "- We thank Irina Gravila from the 2024 MSc in AI for Sustainable Development cohort for providing information about the dataset and the session/code for vizualizing the data on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We first install some Python packages to help with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.7.2 matplotlib==3.10.8 pandas==2.3.3 seaborn==0.13.2 folium==0.20.0\n",
    "%pip install git+https://github.com/adelplanque/geojson@fix-py314 # Use fork supporting Python 3.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We can now load the data. We know from the dataset description and the CSV file that most features are percentages; these can be safely loaded as floating-point numbers. Some features, however, are textual information: these should be loaded using pandas' String dtype, which ensures they will be treated as text rather than numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy.typing as npt\n",
    "import random\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# We assign each feature a human-readable name for convenience\n",
    "HUMAN_READABLE_FEATURES = [\n",
    "    \"ward\",\n",
    "    \"total_households\",\n",
    "    \"total_individuals\",\n",
    "    \"target\",\n",
    "    \"dwelling_brick_concrete\",\n",
    "    \"dwelling_traditional\",\n",
    "    \"dwelling_flat\",\n",
    "    \"dwelling_cluster_complex\",\n",
    "    \"dwelling_semidetached_complex\",\n",
    "    \"dwelling_semidetached\",\n",
    "    \"dwelling_house_backyard\",\n",
    "    \"dwelling_shack_backyard\",\n",
    "    \"dwelling_shack_not_backyard\",\n",
    "    \"dwelling_room\",\n",
    "    \"dwelling_tent_caravan\",\n",
    "    \"dwelling_other\",\n",
    "    \"dwelling_unspecified\",\n",
    "    \"dwelling_na\",\n",
    "    \"school_yes\",\n",
    "    \"school_no\",\n",
    "    \"school_unknown\",\n",
    "    \"school_unspecified\",\n",
    "    \"school_na\",\n",
    "    \"satellite_tv_yes\",\n",
    "    \"satellite_tv_no\",\n",
    "    \"car_yes\",\n",
    "    \"car_no\",\n",
    "    \"landline_yes\",\n",
    "    \"landline_no\",\n",
    "    \"language_afrikaans\",\n",
    "    \"language_english\",\n",
    "    \"language_isindebele\",\n",
    "    \"language_isixhosa\",\n",
    "    \"language_isizulu\",\n",
    "    \"language_sepedi\",\n",
    "    \"language_sesotho\",\n",
    "    \"language_setswana\",\n",
    "    \"language_sign\",\n",
    "    \"language_siswati\",\n",
    "    \"language_tshivenda\",\n",
    "    \"language_xitsonga\",\n",
    "    \"language_other\",\n",
    "    \"language_unspecified\",\n",
    "    \"language_na\",\n",
    "    \"ethnicity_black_african\",\n",
    "    \"ethnicity_coloured\",\n",
    "    \"ethnicity_asian\",\n",
    "    \"ethnicity_white\",\n",
    "    \"ethnicity_other\",\n",
    "    \"electricity_yes\",\n",
    "    \"piped_water_in_dwelling\",\n",
    "    \"piped_water_in_yard\",\n",
    "    \"piped_water_community_0_200_meters\",\n",
    "    \"piped_water_community_200_500_meters\",\n",
    "    \"piped_water_community_500_1000_meters\",\n",
    "    \"piped_water_community_no\",\n",
    "    \"piped_water_community_unspecified\",\n",
    "    \"piped_water_community_na\",\n",
    "    \"piped_water_community_>1000_meters\",\n",
    "    \"ADM4_PCODE\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"nightlights\"\n",
    "]\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    dtypes: dict[str, Any] = defaultdict(pd.Float32Dtype)\n",
    "    dtypes[\"ADM4_PCODE\"] = pd.StringDtype\n",
    "    dtypes[\"ward\"] = pd.StringDtype\n",
    "\n",
    "    return pd.read_csv(path, dtype=dtypes, names=HUMAN_READABLE_FEATURES, header=0)\n",
    "\n",
    "def split_data(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE) # type: ignore\n",
    "\n",
    "df_all = load_dataset(\"Female_headed_household_data/data.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(df_all)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "As usual, we should start by taking at look at the dataset. The authors have conveniently provided a dataset description, which we've included here in `Female_headed_household_data/variable_descriptions.csv`.\n",
    "\n",
    "Have a look at the file: what kind of data do we have? Is it categorical or numerical? Are all features reasonable to use for making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the data\n",
    "We can now plot some graphs showing the distribution of all features in the dataset. There are quite a few, but we can group them to make the exploration a bit simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDs\n",
    "Check the dataset columns and description: there are 2 features which are just names or administrative identifiers for each ward (i.e. each row in the dataset). Would it be useful to plot these?\n",
    "\n",
    "A better idea is to write a small sanity check to see if these features indeed have a unique value for each row. If so, we know that there are no repeated samples in the dataset. It is also safe to drop these columns later as they convey no meaningful information for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_features = []\n",
    "\n",
    "for feature in id_features:\n",
    "    is_unique_per_ward = \n",
    "    if is_unique_per_ward:\n",
    "        print(f\"Feature {feature} is unique for each ward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographical features\n",
    "There are 2 features with a spatial meaning in the dataset. Which ones are they?\n",
    "\n",
    "We can visualise their distribution using histograms. As expected, we should see a range which reflects South Africa's position in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geographical_features = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the data on a map\n",
    "Visualising the data points over the map of South Africa may reveal some patterns. We can plot a point for each ward, as localised by the latitude and longitude features. Colouring the points based on their target value lets us investigate if there is a spatial relationship between data points and targets:\n",
    "- Points are green if their target value is lower than the 25th percentile of the targets\n",
    "- Blue if their target is between the 25th and the 50th percentile\n",
    "- Orange if their target is between the 50th and the 75th percentile\n",
    "- Red if their target is greater than the 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geojson\n",
    "\n",
    "# Get centre of map\n",
    "average_lat = X_train.latitude.mean()\n",
    "average_lon = X_train.longitude.mean()\n",
    "\n",
    "# Add map\n",
    "mymap = folium.Map(location=[average_lat, average_lon], zoom_start=6)\n",
    "\n",
    "# Target quantiles\n",
    "target_quantiles = [np.quantile(y_train, 0.25), \n",
    "                    np.quantile(y_train, 0.50), \n",
    "                    np.quantile(y_train, 0.75)]\n",
    "\n",
    "# Add markers for each location\n",
    "locations = list(zip(X_train.latitude, X_train.longitude, y_train))\n",
    "for lat, lon, target in locations:\n",
    "    color = \"\"\n",
    "    if target < target_quantiles[0]:\n",
    "        color=\"green\"\n",
    "    elif target < target_quantiles[1]:\n",
    "        color=\"blue\"\n",
    "    elif target < target_quantiles[2]:\n",
    "        color=\"orange\"\n",
    "    else:\n",
    "        color=\"red\"\n",
    "\n",
    "    folium.CircleMarker(location=[lat, lon], radius=0.5, color=color, opacity=.6).add_to(mymap)\n",
    "\n",
    "# Get South Africa geometry\n",
    "with open('./Female_headed_household_data/countries.geojson') as f:\n",
    "    gj = geojson.load(f)\n",
    "\n",
    "south_africa_geometry = next(x for x in gj['features'] \n",
    "                             if x['properties']['ISO_A3'] == 'ZAF')\n",
    "\n",
    "# Add South Africa delimitation\n",
    "folium.GeoJson(south_africa_geometry, style_function=lambda x: {\n",
    "        \"fillColor\": \"#ffff00\",\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 1.5}).add_to(mymap)\n",
    "\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that larger target values (red and orange dots) tend to be clustered around the eastern side of the South African shore and the far northeastern side of the country. On the other hand, the smallest target values (blue and green dots) tend to be clustered around the city of Johannesburg, with some points also present along the shore. Thus, this map indicates that the latitude and longitude can be relevant features in the dataset which, when combined, can have a correlation to the target and have the potential to help models in their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentages\n",
    "The vast majority of dataset features represent percentages. There are several groups of options (e.g. dwelling type), with one column representing the prevalence of each option in each ward.\n",
    "\n",
    "For convenience, we group them using the start of their column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_FEATURE_PREFIXES = [\n",
    "    \"dwelling_\",\n",
    "    \"school_\",\n",
    "    \"satellite_tv_\",\n",
    "    \"car_\",\n",
    "    \"landline_\",\n",
    "    \"language_\",\n",
    "    \"ethnicity_\",\n",
    "    \"electricity_\",\n",
    "    \"piped_water_\"\n",
    "]\n",
    "\n",
    "percentage_features = []\n",
    "for prefix in PERCENTAGE_FEATURE_PREFIXES:\n",
    "    for column in X_train.columns:\n",
    "        if column.startswith(prefix):\n",
    "            percentage_features.append(column)\n",
    "\n",
    "percentage_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have a little sanity check for this data. Do all values of the percentage features lie between 0 and 1, as all good percentages should?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they do, so we already know the range of possible values for these features. There are also many of them, so plotting a histogram for each would not be very readable.\n",
    "\n",
    "A better alternative is to plot a bar chart for each group of options (e.g. dwelling types). Each chart shows the possible options along with its mean percentage across wards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes import Axes\n",
    "\n",
    "def plot_mean_percentages(data: pd.DataFrame, feature_prefix: str, axes: Axes) -> None:\n",
    "    \"\"\"\n",
    "    Plots the mean prevalence of each option in a group of options.\n",
    "    The data is plotted as a bar graph in the given axes\n",
    "    \"\"\"\n",
    "    means = {}\n",
    "    for column in [c for c in data.columns if c.startswith(feature_prefix)]:\n",
    "        simplified_name = column.replace(feature_prefix, \"\")\n",
    "        means[simplified_name] = data[column].mean()\n",
    "\n",
    "    axes.set_title(feature_prefix)\n",
    "    axes.set_xlim(0, 1)\n",
    "    axes.barh(list(means.keys()), list(means.values()))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "for i, prefix in enumerate(PERCENTAGE_FEATURE_PREFIXES):\n",
    "    plot_mean_percentages(X_train, prefix, axes[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While interesting, this plot reveals a couple of issues.\n",
    "\n",
    "Firstly, some options seem to be very underrepresented - some may even be always 0. For this exercise, we just want to find the percentages which are always 0 (or any other constant) so we can safely remove them from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_features = []\n",
    "\n",
    "for feature in percentage_features:\n",
    "    if :\n",
    "        constant_features.append(feature)\n",
    "\n",
    "constant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, some features seem redundant: they are both percentages where one feature shows the proportion of \"yes\" and one shows the proportion of \"no\". Assuming that the two sum up to one, it's safe to remove one of the options without losing information.\n",
    "\n",
    "Let's run a quick sanity check to see if the percentages of all options in a group sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_percentages(df: pd.DataFrame, prefix: str):\n",
    "    tot = np.zeros(len(df), dtype=np.float32)\n",
    "    for column in [c for c in df.columns if c.startswith(prefix)]:\n",
    "        tot += df[column].to_numpy().ravel()\n",
    "    return np.all(np.isclose(tot, 1))\n",
    "\n",
    "for prefix in PERCENTAGE_FEATURE_PREFIXES:\n",
    "    is_total_1 = check_percentages(X_train, prefix)\n",
    "    if not is_total_1:\n",
    "        print(f\"Percentages starting with \\\"{prefix}\\\" do not sum up to 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only feature which doesn't is electricity use, which is already sparsely encoded (i.e. it only has 1 option). There are 3 other groups which can be encoded in this way, as they only have one option for \"yes\" and one for \"no\". Add one of their 2 columns to the list below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unconstrained features\n",
    "The last 3 features in the dataset can simply be plotted as histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Now that we've visualised the distributions and uncovered some issues with the data, write a preprocessing `Pipeline` to prepare the data before training.\n",
    "\n",
    "Based on the previous exercises, there are 10 features which can be safely dropped; you can do this in a `ColumnTransformer` using the special \"drop\" keyword.\n",
    "\n",
    "Based on the prevalence of numerical features, you may be tempted to apply a scaler to everything else. Is this a sensible choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "useless_features = [\n",
    "    *id_features,\n",
    "    *redundant_features,\n",
    "    *constant_features\n",
    "]\n",
    "\n",
    "preprocessor = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XnBhXmluxjZ"
   },
   "source": [
    "## Task 1: Linear models\n",
    "In this task, we will train and evaluate some [linear models](https://scikit-learn.org/stable/modules/linear_model.html#). We will investigate the effect of different types and strength of regularisation on our models.\n",
    "\n",
    "These are the models we're going to use:\n",
    "- [Ridge regression](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)\n",
    "- [LASSO](https://scikit-learn.org/stable/modules/linear_model.html#lasso)\n",
    "- [ElasticNet](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)\n",
    "\n",
    "The main difference between them is the type of regularisation. See the lecture notes and the documentation linked above for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK9iHoktuxja"
   },
   "source": [
    "### 1.1 Train and evaluate models\n",
    "Create a pipeline to train and test the linear models with varying regularization settings, and chose the best model for predicting the target. Print the average cross-validation performance (with the standard deviation) as well as the test performance.\n",
    "\n",
    "For Ridge regression and LASSO, only change the strength of the regularisation. Check the scikit docs: which hyperparameter controls this?\n",
    "\n",
    "> To cover a lot of possible values quickly, the hyperparameter ranges should be picked on a log scale\n",
    "\n",
    "For ElasticNet, also change the relative weight of the L2 and L1 norms. In this case, try only 2-4 values: the plotting task later will be hard to read otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI6ym6BFuxja"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "def make_full_pipeline(model: BaseEstimator) -> Pipeline:\n",
    "    return Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "\n",
    "def optimise_hyperparameters(model: Pipeline, hyperparams: dict, X_train: pd.DataFrame, y_train: npt.NDArray[np.float32]):\n",
    "    tuner = GridSearchCV(model,\n",
    "                         cv=5,\n",
    "                         param_grid=hyperparams,\n",
    "                         n_jobs=-1,\n",
    "                         refit=True,\n",
    "                         scoring=\"neg_root_mean_squared_error\")\n",
    "    return tuner.fit(X_train, y_train)\n",
    "\n",
    "# Define the parameter grids for each model\n",
    "alpha_range = \n",
    "\n",
    "ridge_params = {\n",
    "    'regressor__alpha': alpha_range\n",
    "}\n",
    "lasso_params = {\n",
    "    'regressor__alpha': alpha_range\n",
    "}\n",
    "elastic_params = {\n",
    "    'regressor__alpha': alpha_range,\n",
    "    'regressor__l1_ratio':\n",
    "}\n",
    "\n",
    "# Optimise the hyperparameters\n",
    "tuned_ridge = \n",
    "tuned_lasso = \n",
    "tuned_elastic = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's evaluate the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def evaluate_performance(model_name: str, tuner: GridSearchCV, results_df: pd.DataFrame):\n",
    "    cv_test_scores = tuner.cv_results_[\"mean_test_score\"]\n",
    "    cv_score_mean = cv_test_scores.mean()\n",
    "    cv_score_std = cv_test_scores.std()\n",
    "\n",
    "    y_pred = tuner.predict(X_test)\n",
    "    test_score = root_mean_squared_error(y_pred, y_test)\n",
    "\n",
    "    results_df.loc[len(results_df)] = [model_name, tuner.best_params_, -cv_score_mean, cv_score_std, test_score]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best Hyperparameters', 'Mean CV Score (RMSE)', \"CV score std\", 'Test RMSE'])\n",
    "evaluate_performance(\"Ridge\", tuned_ridge, results_df)\n",
    "evaluate_performance(\"LASSO\", tuned_lasso, results_df)\n",
    "evaluate_performance(\"ElasticNet\", tuned_elastic, results_df)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_FLSx8Nuxjb"
   },
   "source": [
    "### 1.2 Plot CV performance as function of hyperparameters\n",
    "Create a plot to show the effect of the regularisation strength on each model's performance. For each model, plot how the CV performance varies as alpha increases.\n",
    "\n",
    "Note that you'll have to plot ElasticNet performance separately for each value of L1 ratio.\n",
    "\n",
    "> Hint: if you're using a log scale, `plt.semilogx` is a good function to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1IHtU9buxjc"
   },
   "outputs": [],
   "source": [
    "def plot_model_performance(grid_search: GridSearchCV, model_name: str, axes: Axes) -> None:\n",
    "    \"\"\" \n",
    "    Plot the error observed in the given grid search\n",
    "    for each value of the regularisation strength hyperparameter.\n",
    "    \"\"\"\n",
    "    axes.set_ylabel(\"RMSE\")\n",
    "    axes.set_xlabel(\"Alpha\")\n",
    "    \n",
    "    if model_name != 'ElasticNet':\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Create a single figure and axis\n",
    "fig, axes = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the performance of each model on the same axis\n",
    "plot_model_performance(tuned_ridge, 'Ridge', axes)\n",
    "plot_model_performance(tuned_lasso, 'Lasso', axes)\n",
    "plot_model_performance(tuned_elastic, 'ElasticNet', axes)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try generating this plot using different hyperparameter ranges for the cross-validation. What does it look like if you try a very broad range? What if you focus on very small values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a significant difference between the 3 models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blbL9yRSuxjc"
   },
   "source": [
    "### 1.3 Plot model coefficients\n",
    "Create figures to show the models coefficients for model interpretation (i.e. including the feature names). For each model, you should show the 10 features with the largest coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5YaEySjuxj4"
   },
   "outputs": [],
   "source": [
    "def plot_top_model_coefficients(tuner: GridSearchCV, model_name: str) -> None:\n",
    "    pass\n",
    "\n",
    "plot_top_model_coefficients(tuned_ridge, \"Ridge\")\n",
    "plot_top_model_coefficients(tuned_lasso, \"Lasso\")\n",
    "plot_top_model_coefficients(tuned_elastic, \"ElasticNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the different models agree with each other? What about looking at the smallest 10 weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Check weight distribution\n",
    "Now plot a histogram showing the distribution of weight magnitudes for the 3 models. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf6E0ZASuxj4"
   },
   "source": [
    "### 1.5 Check model similarity\n",
    "Finally, create a similarity matrix to show the similarity of the coefficients across the different models. Which ones are more similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9gRL6bRuxj5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNw6xH5juxj6"
   },
   "source": [
    "### Discussion: How does the performance compare across models? Are the coefficients similar across models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2c8tPgTuxj7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqxwOPNMuxj8"
   },
   "source": [
    "## Task 2: Tree and ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbECao3Iuxj8"
   },
   "source": [
    "### 2.1 Train models\n",
    "For the same dataset compare the performance of a decision tree and ensemble methods (e.g. bagging, boosting and gradient boosting).\n",
    "\n",
    "Trees: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree  \n",
    "Ensembles: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "ZjW2GANsuxj9",
    "outputId": "c1714867-a8e0-4321-928f-dc1a5f5ef1eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize models\n",
    "decision_tree = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "bagging = BaggingRegressor(random_state=RANDOM_STATE)\n",
    "boosting = AdaBoostRegressor(random_state=RANDOM_STATE)\n",
    "gradient_boosting = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": decision_tree,\n",
    "    \"Bagging\": bagging,\n",
    "    \"Boosting\": boosting,\n",
    "    \"Gradient Boosting\": gradient_boosting\n",
    "}\n",
    "\n",
    "# Define parameter grids\n",
    "decision_tree_params = {'regressor__max_depth': [3, 20]}\n",
    "bagging_params = {'regressor__n_estimators': [5,  50, 100]}\n",
    "boosting_params = {'regressor__n_estimators': [5, 50, 100]}\n",
    "gradient_boosting_params = {'regressor__n_estimators': [5, 50, 100]}\n",
    "\n",
    "# Create a dictionary to hold the parameter grids\n",
    "param_grids = {\n",
    "    \"Decision Tree\": decision_tree_params,\n",
    "    \"Bagging\": bagging_params,\n",
    "    \"Boosting\": boosting_params,\n",
    "    \"Gradient Boosting\": gradient_boosting_params\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best Hyperparameters', 'Mean CV Score (RMSE)', \"CV score std\", 'Test RMSE'])\n",
    "\n",
    "# Use the functions we already defined\n",
    "# to train and evaluate the models\n",
    "fitted_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Fitting {name}\")\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIjGPRJouxj9"
   },
   "source": [
    "### 2.2 Plot feature importances\n",
    "Create figures to show the top 10 features accordingly to feature importance for the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TS4NMbXuxj-"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(model: GridSearchCV, name: str, ax: Axes):\n",
    "    pass\n",
    "\n",
    "# Plotting feature importances for each model\n",
    "for name, model in fitted_models.items():\n",
    "    plot_feature_importances(model, name, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNLVLasluxj-"
   },
   "source": [
    "**Discussion**  \n",
    "**Were the features selected similar across the different models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv6xLX7QkWdB"
   },
   "source": [
    "### 2.3 Pruning trees\n",
    "Compare two different approaches for prunning a decision tree (cost-complexity prunning and max leaves nodes) and plot the resulting trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WVFpMLDkWdC"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
